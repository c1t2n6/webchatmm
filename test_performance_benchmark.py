#!/usr/bin/env python3
"""
Performance Benchmark Test
=========================

Test hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng chat m·ªõi ƒë·ªÉ ƒë√°nh gi√° performance.
"""

import os
import sys
import time
import asyncio
import traceback
from pathlib import Path
from datetime import datetime, timezone, timedelta
import random
import string

# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import modules
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def generate_random_string(length=10):
    """T·∫°o chu·ªói ng·∫´u nhi√™n"""
    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))

def benchmark_import_performance():
    """Benchmark th·ªùi gian import c√°c modules"""
    print("üîç Benchmark Import Performance...")
    
    results = {}
    
    # Test import models
    start_time = time.time()
    try:
        from app.models.chat_models import ChatRoom, ChatMessage, RoomParticipant
        import_time = time.time() - start_time
        results['models'] = import_time
        print(f"‚úÖ Models import: {import_time:.4f}s")
    except Exception as e:
        print(f"‚ùå Models import failed: {e}")
        results['models'] = float('inf')
    
    # Test import schemas
    start_time = time.time()
    try:
        from app.schemas.chat_schemas import ChatRoomCreate, ChatMessageCreate
        import_time = time.time() - start_time
        results['schemas'] = import_time
        print(f"‚úÖ Schemas import: {import_time:.4f}s")
    except Exception as e:
        print(f"‚ùå Schemas import failed: {e}")
        results['schemas'] = float('inf')
    
    # Test import connection manager
    start_time = time.time()
    try:
        from app.websocket.connection_manager import ConnectionManager
        import_time = time.time() - start_time
        results['connection_manager'] = import_time
        print(f"‚úÖ Connection Manager import: {import_time:.4f}s")
    except Exception as e:
        print(f"‚ùå Connection Manager import failed: {e}")
        results['connection_manager'] = float('inf')
    
    # Test import chat service
    start_time = time.time()
    try:
        from app.services.chat_service import ChatService
        import_time = time.time() - start_time
        results['chat_service'] = import_time
        print(f"‚úÖ Chat Service import: {import_time:.4f}s")
    except Exception as e:
        print(f"‚ùå Chat Service import failed: {e}")
        results['chat_service'] = float('inf')
    
    return results

def benchmark_memory_usage():
    """Benchmark memory usage"""
    print("\nüîç Benchmark Memory Usage...")
    
    try:
        import psutil
        import gc
        
        # Force garbage collection
        gc.collect()
        
        # Get initial memory
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Import modules
        from app.models.chat_models import ChatRoom, ChatMessage, RoomParticipant
        from app.schemas.chat_schemas import ChatRoomCreate, ChatMessageCreate
        from app.websocket.connection_manager import ConnectionManager
        from app.services.chat_service import ChatService
        
        # Get memory after import
        gc.collect()
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        memory_increase = final_memory - initial_memory
        
        print(f"‚úÖ Initial memory: {initial_memory:.2f} MB")
        print(f"‚úÖ Final memory: {final_memory:.2f} MB")
        print(f"‚úÖ Memory increase: {memory_increase:.2f} MB")
        
        if memory_increase < 10:
            print("‚úÖ Memory usage t·ªët")
        elif memory_increase < 50:
            print("‚ö†Ô∏è  Memory usage trung b√¨nh")
        else:
            print("‚ùå Memory usage cao")
        
        return {
            'initial': initial_memory,
            'final': final_memory,
            'increase': memory_increase
        }
        
    except ImportError:
        print("‚ö†Ô∏è  psutil kh√¥ng c√≥ s·∫µn, b·ªè qua memory benchmark")
        return None
    except Exception as e:
        print(f"‚ùå Memory benchmark failed: {e}")
        return None

def benchmark_object_creation():
    """Benchmark th·ªùi gian t·∫°o objects"""
    print("\nüîç Benchmark Object Creation...")
    
    try:
        from app.schemas.chat_schemas import ChatRoomCreate, ChatMessageCreate
        
        # Test t·∫°o ChatRoomCreate
        start_time = time.time()
        for i in range(1000):
            room = ChatRoomCreate(
                user2_id=i,
                search_type="chat"
            )
        room_creation_time = time.time() - start_time
        print(f"‚úÖ ChatRoomCreate (1000 objects): {room_creation_time:.4f}s")
        
        # Test t·∫°o ChatMessageCreate
        start_time = time.time()
        for i in range(1000):
            message = ChatMessageCreate(
                content=f"Test message {i}",
                content_type="text",
                room_id=i
            )
        message_creation_time = time.time() - start_time
        print(f"‚úÖ ChatMessageCreate (1000 objects): {message_creation_time:.4f}s")
        
        return {
            'room_creation': room_creation_time,
            'message_creation': message_creation_time
        }
        
    except Exception as e:
        print(f"‚ùå Object creation benchmark failed: {e}")
        traceback.print_exc()
        return None

def benchmark_validation_performance():
    """Benchmark hi·ªáu su·∫•t validation"""
    print("\nüîç Benchmark Validation Performance...")
    
    try:
        from app.schemas.chat_schemas import ChatRoomCreate, ChatMessageCreate
        
        # Test validation v·ªõi d·ªØ li·ªáu h·ª£p l·ªá
        start_time = time.time()
        for i in range(1000):
            room = ChatRoomCreate(
                user2_id=i,
                search_type="chat"
            )
            # Trigger validation
            room_dict = room.model_dump()
        valid_validation_time = time.time() - start_time
        print(f"‚úÖ Valid validation (1000 objects): {valid_validation_time:.4f}s")
        
        # Test validation v·ªõi d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá (s·∫Ω raise exception)
        start_time = time.time()
        invalid_count = 0
        for i in range(100):
            try:
                room = ChatRoomCreate(
                    user2_id=-1,  # Invalid: negative user ID
                    search_type="invalid_type"  # Invalid search type
                )
            except:
                invalid_count += 1
        invalid_validation_time = time.time() - start_time
        print(f"‚úÖ Invalid validation (100 objects): {invalid_validation_time:.4f}s")
        print(f"‚úÖ Invalid objects caught: {invalid_count}/100")
        
        return {
            'valid_validation': valid_validation_time,
            'invalid_validation': invalid_validation_time
        }
        
    except Exception as e:
        print(f"‚ùå Validation benchmark failed: {e}")
        traceback.print_exc()
        return None

def benchmark_serialization_performance():
    """Benchmark hi·ªáu su·∫•t serialization"""
    print("\nüîç Benchmark Serialization Performance...")
    
    try:
        from app.schemas.chat_schemas import ChatRoomCreate, ChatMessageCreate
        
        # T·∫°o test objects
        room = ChatRoomCreate(
            user2_id=1,
            search_type="chat"
        )
        
        message = ChatMessageCreate(
            content="Test message",
            content_type="text",
            room_id=1
        )
        
        # Test JSON serialization
        start_time = time.time()
        for i in range(1000):
            room_json = room.model_dump_json()
        room_serialization_time = time.time() - start_time
        print(f"‚úÖ Room JSON serialization (1000x): {room_serialization_time:.4f}s")
        
        start_time = time.time()
        for i in range(1000):
            message_json = message.model_dump_json()
        message_serialization_time = time.time() - start_time
        print(f"‚úÖ Message JSON serialization (1000x): {message_serialization_time:.4f}s")
        
        # Test dict serialization
        start_time = time.time()
        for i in range(1000):
            room_dict = room.model_dump()
        room_dict_time = time.time() - start_time
        print(f"‚úÖ Room dict serialization (1000x): {room_dict_time:.4f}s")
        
        return {
            'room_json': room_serialization_time,
            'message_json': message_serialization_time,
            'room_dict': room_dict_time
        }
        
    except Exception as e:
        print(f"‚ùå Serialization benchmark failed: {e}")
        traceback.print_exc()
        return None

def benchmark_database_operations():
    """Benchmark hi·ªáu su·∫•t database operations (simulated)"""
    print("\nüîç Benchmark Database Operations (Simulated)...")
    
    try:
        from app.services.chat_service import ChatService
        from app.schemas.chat_schemas import ChatRoomCreate, ChatMessageCreate
        
        # Simulate database operations
        chat_service = ChatService()
        
        # Test cache operations
        start_time = time.time()
        for i in range(1000):
            # Simulate cache operations
            cache_key = f"room:{i}"
            cache_value = {"id": i, "name": f"Room {i}"}
            # In real scenario, this would use Redis or in-memory cache
        cache_time = time.time() - start_time
        print(f"‚úÖ Cache operations (1000x): {cache_time:.4f}s")
        
        # Test message processing simulation
        start_time = time.time()
        for i in range(1000):
            # Simulate message processing
            message_data = {
                "content": f"Message {i}",
                "content_type": "text",
                "user_id": i % 100,
                "room_id": i % 50
            }
            # In real scenario, this would process and store messages
        message_processing_time = time.time() - start_time
        print(f"‚úÖ Message processing simulation (1000x): {message_processing_time:.4f}s")
        
        return {
            'cache_operations': cache_time,
            'message_processing': message_processing_time
        }
        
    except Exception as e:
        print(f"‚ùå Database operations benchmark failed: {e}")
        traceback.print_exc()
        return None

def generate_performance_report(all_results):
    """T·∫°o b√°o c√°o hi·ªáu su·∫•t t·ªïng h·ª£p"""
    print("\n" + "="*60)
    print("üìä B√ÅO C√ÅO HI·ªÜU SU·∫§T T·ªîNG H·ª¢P")
    print("="*60)
    
    # Import performance
    if 'import_performance' in all_results:
        print("\nüöÄ IMPORT PERFORMANCE:")
        for module, time_taken in all_results['import_performance'].items():
            status = "‚úÖ T·ªêT" if time_taken < 0.1 else "‚ö†Ô∏è  TRUNG B√åNH" if time_taken < 0.5 else "‚ùå CH·∫¨M"
            print(f"   {module}: {time_taken:.4f}s - {status}")
    
    # Memory usage
    if 'memory_usage' in all_results and all_results['memory_usage']:
        print("\nüíæ MEMORY USAGE:")
        memory = all_results['memory_usage']
        print(f"   Memory increase: {memory['increase']:.2f} MB")
        if memory['increase'] < 10:
            print("   Status: ‚úÖ T·ªêT")
        elif memory['increase'] < 50:
            print("   Status: ‚ö†Ô∏è  TRUNG B√åNH")
        else:
            print("   Status: ‚ùå CAO")
    
    # Object creation
    if 'object_creation' in all_results:
        print("\nüèóÔ∏è  OBJECT CREATION:")
        obj_creation = all_results['object_creation']
        for operation, time_taken in obj_creation.items():
            status = "‚úÖ T·ªêT" if time_taken < 0.1 else "‚ö†Ô∏è  TRUNG B√åNH" if time_taken < 0.5 else "‚ùå CH·∫¨M"
            print(f"   {operation}: {time_taken:.4f}s - {status}")
    
    # Validation
    if 'validation_performance' in all_results:
        print("\n‚úÖ VALIDATION PERFORMANCE:")
        validation = all_results['validation_performance']
        for operation, time_taken in validation.items():
            status = "‚úÖ T·ªêT" if time_taken < 0.1 else "‚ö†Ô∏è  TRUNG B√åNH" if time_taken < 0.5 else "‚ùå CH·∫¨M"
            print(f"   {operation}: {time_taken:.4f}s - {status}")
    
    # Serialization
    if 'serialization_performance' in all_results:
        print("\nüì§ SERIALIZATION PERFORMANCE:")
        serialization = all_results['serialization_performance']
        for operation, time_taken in serialization.items():
            status = "‚úÖ T·ªêT" if time_taken < 0.1 else "‚ö†Ô∏è  TRUNG B√åNH" if time_taken < 0.5 else "‚ùå CH·∫¨M"
            print(f"   {operation}: {time_taken:.4f}s - {status}")
    
    # Database operations
    if 'database_operations' in all_results:
        print("\nüóÑÔ∏è  DATABASE OPERATIONS (SIMULATED):")
        db_ops = all_results['database_operations']
        for operation, time_taken in db_ops.items():
            status = "‚úÖ T·ªêT" if time_taken < 0.1 else "‚ö†Ô∏è  TRUNG B√åNH" if time_taken < 0.5 else "‚ùå CH·∫¨M"
            print(f"   {operation}: {time_taken:.4f}s - {status}")
    
    # Overall assessment
    print("\nüéØ ƒê√ÅNH GI√Å T·ªîNG TH·ªÇ:")
    
    # Count performance levels
    total_tests = 0
    good_tests = 0
    medium_tests = 0
    slow_tests = 0
    
    for category, results in all_results.items():
        if isinstance(results, dict):
            for operation, time_taken in results.items():
                if isinstance(time_taken, (int, float)):
                    total_tests += 1
                    if time_taken < 0.1:
                        good_tests += 1
                    elif time_taken < 0.5:
                        medium_tests += 1
                    else:
                        slow_tests += 1
    
    if total_tests > 0:
        good_percentage = (good_tests / total_tests) * 100
        medium_percentage = (medium_tests / total_tests) * 100
        slow_percentage = (slow_tests / total_tests) * 100
        
        print(f"   T·ªïng s·ªë tests: {total_tests}")
        print(f"   T·ªêT: {good_tests} ({good_percentage:.1f}%)")
        print(f"   TRUNG B√åNH: {medium_tests} ({medium_percentage:.1f}%)")
        print(f"   CH·∫¨M: {slow_tests} ({slow_percentage:.1f}%)")
        
        if good_percentage >= 80:
            print("   üéâ H·ªá th·ªëng c√≥ hi·ªáu su·∫•t R·∫§T T·ªêT!")
        elif good_percentage >= 60:
            print("   ‚úÖ H·ªá th·ªëng c√≥ hi·ªáu su·∫•t T·ªêT")
        elif good_percentage >= 40:
            print("   ‚ö†Ô∏è  H·ªá th·ªëng c√≥ hi·ªáu su·∫•t TRUNG B√åNH")
        else:
            print("   ‚ùå H·ªá th·ªëng c√≥ hi·ªáu su·∫•t CH·∫¨M, c·∫ßn t·ªëi ∆∞u h√≥a")

def main():
    """Main function"""
    print("üöÄ B·∫Øt ƒë·∫ßu Performance Benchmark Test...")
    print("="*50)
    
    all_results = {}
    
    try:
        # Run all benchmarks
        all_results['import_performance'] = benchmark_import_performance()
        all_results['memory_usage'] = benchmark_memory_usage()
        all_results['object_creation'] = benchmark_object_creation()
        all_results['validation_performance'] = benchmark_validation_performance()
        all_results['serialization_performance'] = benchmark_serialization_performance()
        all_results['database_operations'] = benchmark_database_operations()
        
        # Generate performance report
        generate_performance_report(all_results)
        
        print("\n‚úÖ Performance benchmark ho√†n th√†nh!")
        
    except Exception as e:
        print(f"‚ùå L·ªói trong benchmark: {e}")
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
